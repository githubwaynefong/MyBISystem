package com.etl.mapreduce;

import java.io.IOException;
import java.net.URI;

import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import com.etl.utls.IpParser4LocalCache;
import com.etl.utls.LogParser;
import com.etl.utls.LogParserFactory;


public class ClickStreamMapper extends Mapper<LongWritable, Text, Text, Text> {
	
	
	@Override
	protected void setup(Mapper<LongWritable, Text, Text, Text>.Context context)
			throws IOException, InterruptedException {
		// TODO Auto-generated method stub
		super.setup(context);
		URI[] cacheFile = context.getCacheFiles();
		//HDFS缓存路径
//		System.out.println("cacheFile[0].toString() : " + cacheFile[0].toString());
		FileSystem fs = FileSystem.get(context.getConfiguration());
		//本地缓存路径
		Path LocalCachePath = new Path("/home/hadoop/cache/qqwry.dat");
		//将HDFS分布式文件系统中文件缓存到计算节点本地
		fs.copyToLocalFile(new Path(cacheFile[0]), LocalCachePath);
		//设置IP解析器访问本地缓存数据库文件
		IpParser4LocalCache.setDbPath(LocalCachePath.toString());
	}
	
	
	@Override
	protected void map(LongWritable key, Text value, Context context) 
			throws IOException, InterruptedException {
		//注：此map的输入key为文本行号，value为单行文本
		String log = value.toString();
		
		//获取当前Mapper对象注册的LogParser对象，解析log日志
		LogParser logParser = LogParserFactory.getInstance();
		logParser.parse(log);
		
		//用sessionId和receiveTime组成新的key
		String mapOutKey = logParser.getSessionId() + "&" + logParser.getReceiveTime();
		//按照clickstream_log表的顺序重新组合这些字段
		String mapOutValue = logParser.getIpAddress() + "\t" + logParser.getUniqueId() + "\t" 
				+ logParser.getUrl() + "\t" + logParser.getSessionId() + "\t" 
				+ logParser.getSessionTimes() + "\t" + logParser.getAreaAddress() + "\t" 
				+ logParser.getLocalAddress() + "\t" + logParser.getBrowserType() + "\t" 
				+ logParser.getOperationSys() + "\t" + logParser.getReferUrl() + "\t" 
				+ logParser.getReceiveTime() + "\t" + logParser.getUserId();
		
		context.write(new Text(mapOutKey), new Text(mapOutValue));
	}
	
	@Override
	protected void cleanup(Mapper<LongWritable, Text, Text, Text>.Context context)
			throws IOException, InterruptedException {
		// TODO Auto-generated method stub
		super.cleanup(context);
		if(fs.exists(LocalCachePath)) {
			System.out.println("fs.exists(LocalCachePath) ： " + fs.exists(LocalCachePath));
			fs.mkdirs(LocalCachePath);
		}
	}
}
